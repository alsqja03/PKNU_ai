import streamlit as st
import openai
import time
import PyPDF2
import numpy as np

st.set_page_config(page_title="GPT-4o Mini Web App", layout="centered")

# session_state ì´ˆê¸°í™”
if "api_key" not in st.session_state:
    st.session_state.api_key = ""
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []
if "library_chat_history" not in st.session_state:
    st.session_state.library_chat_history = []
if "pdf_file_id" not in st.session_state:
    st.session_state.pdf_file_id = None
if "assistant_id" not in st.session_state:
    st.session_state.assistant_id = None
if "thread_id" not in st.session_state:
    st.session_state.thread_id = None
if "vector_store_id" not in st.session_state:
    st.session_state.vector_store_id = None
if "clear_flag" not in st.session_state:
    st.session_state.clear_flag = False
if "qa_input" not in st.session_state:
    st.session_state.qa_input = ""
if "chat_input" not in st.session_state:
    st.session_state.chat_input = ""
if "library_input" not in st.session_state:
    st.session_state.library_input = ""
if "pdf_input" not in st.session_state:
    st.session_state.pdf_input = ""
if "pdf_chunks" not in st.session_state:
    st.session_state.pdf_chunks = []
if "pdf_embeddings" not in st.session_state:
    st.session_state.pdf_embeddings = []

page = st.sidebar.selectbox("í˜ì´ì§€ ì„ íƒ", ["Q&A", "Chat", "Chatbot", "ChatPDF"])

st.session_state.api_key = st.sidebar.text_input(
    "OpenAI API Key ì…ë ¥",
    type="password",
    value=st.session_state.api_key,
)

if st.sidebar.button("API Key ì´ˆê¸°í™”"):
    st.session_state.api_key = ""

def get_client():
    return openai.OpenAI(api_key=st.session_state.api_key)

@st.cache_data
def get_response(api_key: str, messages: list) -> str:
    client = openai.OpenAI(api_key=api_key)
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=messages,
        temperature=0.7,
    )
    return response.choices[0].message.content.strip()

def extract_text_from_pdf(file) -> str:
    reader = PyPDF2.PdfReader(file)
    return "\n".join([page.extract_text() or "" for page in reader.pages])

def chunk_text(text: str, max_tokens=500) -> list[str]:
    sentences = text.split(". ")
    chunks = []
    chunk = ""
    for sentence in sentences:
        if len(chunk + sentence) < max_tokens:
            chunk += sentence + ". "
        else:
            chunks.append(chunk.strip())
            chunk = sentence + ". "
    if chunk:
        chunks.append(chunk.strip())
    return chunks

def embed_chunks(chunks: list[str]):
    client = get_client()
    clean_chunks = [chunk for chunk in chunks if isinstance(chunk, str) and chunk.strip()]
    if not clean_chunks:
        raise ValueError("ì…ë ¥í•  ìœ íš¨í•œ í…ìŠ¤íŠ¸ ì²­í¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
    response = client.embeddings.create(
        input=clean_chunks,
        model="text-embedding-3-small"
    )
    return [item.embedding for item in response.data]

def cosine_similarity(a, b):
    a = np.array(a)
    b = np.array(b)
    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))

def search_similar_chunks(query: str, chunks: list[str], embeddings: list[list[float]], k=3):
    if not isinstance(query, str) or not query.strip():
        raise ValueError("QueryëŠ” ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
    
    client = get_client()
    query_embedding = client.embeddings.create(
        input=[query],
        model="text-embedding-3-small"
    ).data[0].embedding
    
    similarities = [cosine_similarity(query_embedding, emb) for emb in embeddings]
    top_indices = np.argsort(similarities)[::-1][:k]
    return "\n\n".join([chunks[i] for i in top_indices])

def ask_pdf_bot(query: str, context: str):
    client = get_client()
    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": "ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:\n" + context},
            {"role": "user", "content": query}
        ]
    )
    return response.choices[0].message.content.strip()

def get_single_response(prompt: str):
    client = get_client()
    response = client.chat.completions.create(
        model="gpt-4-1106-preview",
        messages=[
            {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ë¹„ì„œì…ë‹ˆë‹¤."},
            {"role": "user", "content": prompt}
        ]
    )
    return response.choices[0].message.content.strip()

def reset_session_state():
    st.session_state.clear_flag = False
    st.session_state.chat_history = []
    st.session_state.library_chat_history = []
    st.session_state.pdf_file_id = None
    st.session_state.assistant_id = None
    st.session_state.thread_id = None
    st.session_state.vector_store_id = None
    st.session_state.qa_input = ""
    st.session_state.chat_input = ""
    st.session_state.library_input = ""
    st.session_state.pdf_input = ""
    st.session_state.pdf_chunks = []
    st.session_state.pdf_embeddings = []

if page == "Q&A":
    st.title("GPT-4o Mini ì§ˆë¬¸ ì‘ë‹µê¸°")
    col1, col2 = st.columns([1, 1])
    with col2:
        if st.button("Clear"):
            reset_session_state()

    st.session_state.qa_input = st.text_area("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:", value=st.session_state.qa_input, height=100)
    if st.button("ì§ˆë¬¸í•˜ê¸°"):
        if st.session_state.qa_input.strip() == "":
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        elif not st.session_state.api_key:
            st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                messages = [
                    {"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": st.session_state.qa_input}
                ]
                answer = get_response(st.session_state.api_key, messages)
                st.subheader("ì‘ë‹µ:")
                st.write(answer)

elif page == "Chat":
    st.title("GPT-4o Mini ì±—ë´‡")
    col1, col2 = st.columns([1, 1])
    with col2:
        if st.button("Clear"):
            reset_session_state()

    st.session_state.chat_input = st.text_area("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", value=st.session_state.chat_input, height=100)
    if st.button("ì§ˆë¬¸í•˜ê¸°"):
        if st.session_state.chat_input.strip() == "":
            st.warning("ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        elif not st.session_state.api_key:
            st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.session_state.chat_history.append({"role": "user", "content": st.session_state.chat_input})
            messages = [{"role": "system", "content": "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ìš©í•œ ì±—ë´‡ì…ë‹ˆë‹¤."}] + st.session_state.chat_history
            assistant_reply = get_response(st.session_state.api_key, messages)
            st.session_state.chat_history.append({"role": "assistant", "content": assistant_reply})
    for msg in st.session_state.chat_history:
        role = "ì‚¬ìš©ì" if msg["role"] == "user" else "GPT"
        st.markdown(f"**{role}:** {msg['content']}")

elif page == "Chatbot":
    st.title("êµ­ë¦½ë¶€ê²½ëŒ€í•™êµ ë„ì„œê´€ ì±—ë´‡")
    col1, col2 = st.columns([1, 1])
    with col2:
        if st.button("Clear"):
            reset_session_state()

    st.session_state.library_input = st.text_area("ë„ì„œê´€ì— ëŒ€í•´ ê¶ê¸ˆí•œ ì ì„ ì…ë ¥í•˜ì„¸ìš”:", value=st.session_state.library_input, height=100)
    library_regulations = load_rules()
    if st.button("ì§ˆë¬¸í•˜ê¸°"):
        if st.session_state.library_input.strip() == "":
            st.warning("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.")
        elif not st.session_state.api_key:
            st.warning("API Keyë¥¼ ì…ë ¥í•˜ì„¸ìš”.")
        else:
            st.session_state.library_chat_history.append({"role": "user", "content": st.session_state.library_input})
            messages = [
                {"role": "system", "content": f"ë‹¹ì‹ ì€ êµ­ë¦½ë¶€ê²½ëŒ€í•™êµ ë„ì„œê´€ ê·œì •ì— ëŒ€í•´ ì•ˆë‚´í•˜ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤. ë‹¤ìŒì€ ë„ì„œê´€ ê·œì •ì…ë‹ˆë‹¤:\n{library_regulations}"}
            ] + st.session_state.library_chat_history
            assistant_reply = get_response(st.session_state.api_key, messages)
            st.session_state.library_chat_history.append({"role": "assistant", "content": assistant_reply})
    for msg in st.session_state.library_chat_history:
        role = "ì‚¬ìš©ì" if msg["role"] == "user" else "ë„ì„œê´€ ì±—ë´‡"
        st.markdown(f"**{role}:** {msg['content']}")

elif page == "ChatPDF":
    st.title("ChatPDF - PDF ê¸°ë°˜ ì±—ë´‡")
    uploaded_file = st.file_uploader("PDF íŒŒì¼ ì—…ë¡œë“œ", type="pdf")
    if st.button("Clear PDF", key="clear_button_chatpdf"):
        st.session_state.pdf_chunks = []
        st.session_state.pdf_embeddings = []
        st.success("PDF ë°ì´í„°ê°€ ì´ˆê¸°í™”ë˜ì—ˆìŠµë‹ˆë‹¤.")

    if uploaded_file and st.session_state.api_key:
        with st.spinner("PDF ë¶„ì„ ì¤‘..."):
            raw_text = extract_text_from_pdf(uploaded_file)
            chunks = chunk_text(raw_text)
            embeddings = embed_chunks(chunks)

            st.session_state.pdf_chunks = chunks
            st.session_state.pdf_embeddings = embeddings
            st.success(f"{len(chunks)}ê°œì˜ ì²­í¬ë¡œ ë¶„í•  ë° ì„ë² ë”© ì™„ë£Œ!")

    if st.session_state.pdf_chunks:
        query = st.text_input("PDF ë‚´ìš© ê¸°ë°˜ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”:")
        if query:
            with st.spinner("ì‘ë‹µ ìƒì„± ì¤‘..."):
                context = search_similar_chunks(query, st.session_state.pdf_chunks, st.session_state.pdf_embeddings)
                answer = ask_pdf_bot(query, context)
                st.markdown("### ğŸ“„ GPT ì‘ë‹µ")
                st.write(answer)

def load_rules():
    try:
        with open("library_rules.txt", "r", encoding="utf-8") as f:
            return f.read()
    except FileNotFoundError:
        return "ë„ì„œê´€ ê·œì • íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
